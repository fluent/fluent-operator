# Default values for fluentbit-operator.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

#Set this to containerd or crio if you want to collect CRI format logs
containerRuntime: docker
#  If you want to deploy a default Fluent Bit pipeline (including Fluent Bit Input, Filter, and output) to collect Kubernetes logs, you'll need to set the Kubernetes parameter to true
# see https://github.com/fluent/fluent-operator/tree/master/manifests/logging-stack
Kubernetes: true

operator:
# The init container is to get the actual storage path of the docker log files so that it can be mounted to collect the logs.
# see https://github.com/fluent/fluent-operator/blob/master/manifests/setup/fluent-operator-deployment.yaml#L26
  initcontainer:
    repository: "docker"
    tag: "20.10"
  container:
    repository: "kubesphere/fluent-operator"
    tag: "latest"
    # FluentBit operator resources. Usually user needn't to adjust these.
  resources:
    limits:
      cpu: 100m
      memory: 60Mi
    requests:
      cpu: 100m
      memory: 20Mi
  # Specify custom annotations to be added to each Fluent Operator pod.
  annotations: {}
  ## Reference to one or more secrets to be used when pulling images
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  imagePullSecrets: []
  # - name: "image-pull-secret"
  # Reference one more key-value pairs of labels that should be attached to fluent-operator
  labels: {}
#  myExampleLabel: someValue
  logPath:
    # The operator currently assumes a Docker container runtime path for the logs as the default, for other container runtimes you can set the location explicitly below.
    # crio: /var/log
    containerd: /var/log

fluentbit:
  image:
    repository: "kubesphere/fluent-bit"
    tag: "v2.0.9"
  # fluentbit resources. If you do want to specify resources, adjust them as necessary
  #You can adjust it based on the log volume.
  resources:
    limits:
      cpu: 500m
      memory: 200Mi
    requests:
      cpu: 10m
      memory: 25Mi
  # Specify custom annotations to be added to each FluentBit pod.
  annotations: {}
    ## Request to Fluent Bit to exclude or not the logs generated by the Pod.
    # fluentbit.io/exclude: "true"
    ## Prometheus can use this tag to automatically discover the Pod and collect monitoring data
    # prometheus.io/scrape: "true"
  # Specify additional custom labels for fluentbit-pods
  labels: {}

  ## Reference to one or more secrets to be used when pulling images
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ##
  imagePullSecrets: [ ]
  # - name: "image-pull-secret"
  secrets: []
  # List of volumes that can be mounted by containers belonging to the pod.
  additionalVolumes: []
  # Pod volumes to mount into the container's filesystem.
  additionalVolumesMounts: []

  # Remove the above empty volumes and volumesMounts, and then set additionalVolumes and additionalVolumesMounts as below if you want to collect node exporter metrics
# additionalVolumes:
#   - name: hostProc
#     hostPath:
#       path: /proc/
#   - name: hostSys
#     hostPath:
#       path: /sys/
# additionalVolumesMounts:
#   - mountPath: /host/sys
#     mountPropagation: HostToContainer
#     name: hostSys
#     readOnly: true
#   - mountPath: /host/proc
#     mountPropagation: HostToContainer
#     name: hostProc
#     readOnly: true

  #Set a limit of memory that Tail plugin can use when appending data to the Engine.
  # You can find more details here: https://docs.fluentbit.io/manual/pipeline/inputs/tail#config
  #If the limit is reach, it will be paused; when the data is flushed it resumes.
  #if the inbound traffic is less than 2.4Mbps, setting memBufLimit to 5MB is enough
  #if the inbound traffic is less than 4.0Mbps, setting memBufLimit to 10MB is enough
  #if the inbound traffic is less than 13.64Mbps, setting memBufLimit to 50MB is enough
  input:
    tail:
      memBufLimit: 5MB
    nodeExporterMetrics: {}
    # uncomment below nodeExporterMetrics section if you want to collect node exporter metrics
#   nodeExporterMetrics:
#     tag: node_metrics
#     scrapeInterval: 15s
#     path:
#       procfs: /host/proc
#       sysfs: /host/sys

  #Configure the output plugin parameter in FluentBit.
  #You can set enable to true to output logs to the specified location.
  output:
#  You can find more supported output plugins here: https://github.com/fluent/fluent-operator/tree/master/docs/plugins/fluentbit/clusteroutput
    es:
      enable: false
      host: "<Elasticsearch url like elasticsearch-logging-data.kubesphere-logging-system.svc>"
      port: 9200
      logstashPrefix: ks-logstash-log
#      path: ""
#      bufferSize: "4KB"
#      index: "fluent-bit"
#      httpUser:
#      httpPassword:
#      logstashFormat: true
#      replaceDots: false
#      enableTLS: false
#      tls:
#        verify: On
#        debug: 1
#        caFile: "<Absolute path to CA certificate file>"
#        caPath: "<Absolute path to scan for certificate files>"
#        crtFile: "<Absolute path to private Key file>"
#        keyFile: "<Absolute path to private Key file>"
#        keyPassword:
#        vhost: "<Hostname to be used for TLS SNI extension>"
    kafka:
      enable: false
      brokers: "<kafka broker list like xxx.xxx.xxx.xxx:9092,yyy.yyy.yyy.yyy:9092>"
      topics: ks-log
    opentelemetry: {}
# You can configure the opentelemetry-related configuration here
    opensearch: {}
# You can configure the opensearch-related configuration here
    stdout:
      enable: true

  #Configure the default filters in FluentBit.
  # The `filter` will filter and parse the collected log information and output the logs into a uniform format. You can choose whether to turn this on or not.
  filter:
    kubernetes:
      enable: true
      labels: false
      annotations: false
    containerd:
  # This is customized lua containerd log format converter, you can refer here:
  # https://github.com/fluent/fluent-operator/blob/master/charts/fluent-operator/templates/fluentbit-clusterfilter-containerd.yaml
  # https://github.com/fluent/fluent-operator/blob/master/charts/fluent-operator/templates/fluentbit-containerd-config.yaml
      enable: true
    systemd:
      enable: true

fluentd:
  enable: false
  name: fluentd
  port: 24224
  image:
    repository: "kubesphere/fluentd"
    tag: "v1.15.3"
  replicas: 1
  forward:
    port: 24224
  watchedNamespaces:
    - kube-system
    - default
  resources:
    limits:
      cpu: 500m
      memory: 500Mi
    requests:
      cpu: 100m
      memory: 128Mi
  # Configure the output plugin parameter in Fluentd.
  # Fluentd is disabled by default, if you enable it make sure to also set up an output to use.
  output:
    es:
      enable: false
      host: elasticsearch-logging-data.kubesphere-logging-system.svc
      port: 9200
      logstashPrefix: ks-logstash-log
      buffer:
        enable: false
        type: file
        path: /buffers/es
    kafka:
      enable: false
      brokers: "my-cluster-kafka-bootstrap.default.svc:9091,my-cluster-kafka-bootstrap.default.svc:9092,my-cluster-kafka-bootstrap.default.svc:9093"
      topicKey: kubernetes_ns
      buffer:
        enable: false
        type: file
        path: /buffers/kafka

nameOverride: ""
fullnameOverride: ""
namespaceOverride: ""
